{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# SPARQL generation with pre-trained GPT for KG Question Answering"
      ],
      "metadata": {
        "id": "Ybl6lHKvweIf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Data processing and Libraries"
      ],
      "metadata": {
        "id": "S0VfgKcNTPrR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "id": "uAloa17_Rbdq",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "173223eb-b497-4260-86c6-6b615aea1fff"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "!gdown 1sl_YdyiucWmk8Lx2x-Qn5ALcr2bLFUb0\n",
        "!unzip DBLP-QuAD.zip"
      ],
      "metadata": {
        "id": "zXjIkCLjTFAk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%%capture\n",
        "import json\n",
        "import requests\n",
        "import re\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import functional as F\n",
        "from torch.nn.modules.module import T\n",
        "from random import shuffle\n",
        "\n",
        "torch.manual_seed(1706)\n",
        "\n",
        "def repl_func(match):\n",
        "    return match.group(1).lower()\n",
        "\n",
        "def get_entities(question, label_generator=\"t5-small\", embedding_reranker=\"distmult\"):\n",
        "    base_url = \"https://ltdemos.informatik.uni-hamburg.de/dblplinkapi/api/entitylinker\"\n",
        "    endpoint_url = f\"{base_url}/{label_generator}/{embedding_reranker}\"\n",
        "    payload = {\"question\": question}\n",
        "    headers = {\"Content-Type\": \"application/json\"}\n",
        "    response = requests.post(endpoint_url, data=json.dumps(payload), headers=headers)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(f\"Error {response.status_code}: {response.text}\")\n",
        "        return None\n",
        "\n",
        "def process_question(entities, question):\n",
        "  new_entities = get_entities(question)[\"entitylinkingresults\"]\n",
        "  found = 0\n",
        "  for entity in new_entities:\n",
        "    label = entity[\"label\"]\n",
        "    if label:\n",
        "      if \": \" in label: label = label.split(\": \")[1] # prune authors\n",
        "      if \". (\" in label: label = label.split(\". (\")[0] # prune year\n",
        "      if label[-1] == \".\": label = label[:-1] # prune last dot\n",
        "      if  (type(entity[\"result\"]) is list and entity[\"result\"] and\n",
        "          type(entity[\"result\"][0]) is list and len(entity[\"result\"][0]) > 1 and\n",
        "          type(entity[\"result\"][0][1]) is list and entity[\"result\"][0][1]):\n",
        "        iri = entity[\"result\"][0][1][0]\n",
        "        if (\"'\" + label + \"'\" in question) and (iri in entities):\n",
        "          found += 1\n",
        "          question = question.replace(\"'\" + label + \"'\", iri)\n",
        "        elif (label in question) and (iri in entities):\n",
        "          found += 1\n",
        "          question = question.replace(label, iri)\n",
        "        elif (len(label.split(\" \")) == 2) and (iri in entities): # If name has given and last name, try 4 combinations\n",
        "          given, last = label.split(\" \")\n",
        "          if given and last:\n",
        "            if last + \", \" + given in question:\n",
        "              found += 1\n",
        "              question = question.replace(last + \", \" + given, iri)\n",
        "            elif last + \", \" + given[0] + \".\" in question:\n",
        "              found += 1\n",
        "              question = question.replace(last + \", \" + given[0] + \".\", iri)\n",
        "            elif given[0] + \".\" + last in question:\n",
        "              found += 1\n",
        "              question = question.replace(given[0] + \".\" + last, iri)\n",
        "            elif given + last[0] + \".\" in question:\n",
        "              found += 1\n",
        "              question = question.replace(given + last[0] + \".\", iri)\n",
        "\n",
        "  if found == len(entities): return question\n",
        "  else: return \"\"\n",
        "\n",
        "def format_question(question): # punctuation can damage the undestanding when attached to a word\n",
        "  question = re.sub(r'^(.)', repl_func, question)\n",
        "  if question[-1] == \".\": question = question[:-1] # eliminate end dot\n",
        "  question = question.replace(\"?\", \"\") # eliminate question mark\n",
        "  return question"
      ],
      "metadata": {
        "id": "hHRGdoxmZk25"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def process_question_entities(question):\n",
        "  new_entities = get_entities(question)[\"entitylinkingresults\"]\n",
        "  entities = []\n",
        "  for entity in new_entities:\n",
        "    label = entity[\"label\"]\n",
        "    if label:\n",
        "      if \": \" in label: label = label.split(\": \")[1] # prune authors\n",
        "      if \". (\" in label: label = label.split(\". (\")[0] # prune year\n",
        "      if label[-1] == \".\": label = label[:-1] # prune last dot\n",
        "      if  (type(entity[\"result\"]) is list and entity[\"result\"] and\n",
        "          type(entity[\"result\"][0]) is list and len(entity[\"result\"][0]) > 1 and\n",
        "          type(entity[\"result\"][0][1]) is list and entity[\"result\"][0][1]):\n",
        "        iri = entity[\"result\"][0][1][0]\n",
        "        if (\"'\" + label + \"'\" in question):\n",
        "          question = question.replace(\"'\" + label + \"'\", iri)\n",
        "          entities.append(iri)\n",
        "        elif (label in question):\n",
        "          question = question.replace(label, iri)\n",
        "          entities.append(iri)\n",
        "        elif (len(label.split(\" \")) == 2): # If name has given and last name, try 4 combinations\n",
        "          given, last = label.split(\" \")\n",
        "          if given and last:\n",
        "            if last + \", \" + given in question:\n",
        "              question = question.replace(last + \", \" + given, iri)\n",
        "              entities.append(iri)\n",
        "            elif last + \", \" + given[0] + \".\" in question:\n",
        "              question = question.replace(last + \", \" + given[0] + \".\", iri)\n",
        "              entities.append(iri)\n",
        "            elif given[0] + \".\" + last in question:\n",
        "              question = question.replace(given[0] + \".\" + last, iri)\n",
        "              entities.append(iri)\n",
        "            elif given + last[0] + \".\" in question:\n",
        "              question = question.replace(given + last[0] + \".\", iri)\n",
        "              entities.append(iri)\n",
        "\n",
        "  return question, entities"
      ],
      "metadata": {
        "id": "uXoUeoaF-SVF"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "questions = []\n",
        "archives = [\"DBLP-QuAD/train/questions.json\"] #\"DBLP-QuAD/valid/questions.json\", \"DBLP-QuAD/test/questions.json\"]\n",
        "for archive in archives:\n",
        "  with open(archive, 'r', encoding='utf-8') as file:\n",
        "    data = json.load(file)\n",
        "    index = 0\n",
        "    for entry in data[\"questions\"][4000:]:\n",
        "      print(index)\n",
        "      index += 1\n",
        "      if entry[\"template_id\"] != \"TP61\":\n",
        "        query = entry[\"query\"][\"sparql\"]\n",
        "\n",
        "        question = format_question(entry[\"question\"][\"string\"])\n",
        "        question = process_question(entry[\"entities\"], question)\n",
        "        if question:\n",
        "          questions.append((question, query))\n",
        "\n",
        "        paraphrased = format_question(entry[\"paraphrased_question\"][\"string\"])\n",
        "        paraphrased = process_question(entry[\"entities\"], paraphrased)\n",
        "        if paraphrased:\n",
        "          questions.append((paraphrased, query))\n",
        "\n",
        "with open(\"/content/drive/MyDrive/DLBP-QuAD-train2.txt\", 'wb') as file:\n",
        "  pickle.dump(questions, file)\n",
        "print(len(questions))"
      ],
      "metadata": {
        "id": "5anHUyA8TWqz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "archives = [\"/content/drive/MyDrive/DLBP-QuAD-valid1.txt\", \"/content/drive/MyDrive/DLBP-QuAD-valid2.txt\",\n",
        "            \"/content/drive/MyDrive/DLBP-QuAD-test.txt\", \"/content/drive/MyDrive/DLBP-QuAD-train1.txt\",\n",
        "            \"/content/drive/MyDrive/DLBP-QuAD-train2.txt\"]\n",
        "questions = []\n",
        "for archive in archives:\n",
        "  with open(archive, 'rb') as file:\n",
        "    data = pickle.load(file)\n",
        "    questions += data"
      ],
      "metadata": {
        "id": "x6y1zbqsxirS"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "questions2 = []\n",
        "for w, q in questions:\n",
        "  if \"'\" not in w:\n",
        "    w = w.replace(\"(\", \"( \").replace(\")\", \" )\")\n",
        "    q = q.replace(\"(\", \"( \").replace(\")\", \" )\")\n",
        "    questions2.append((w, q))\n",
        "questions = questions2\n",
        "print(\"Size of new entity linked dataset:\", len(questions))"
      ],
      "metadata": {
        "id": "GV3l57b-YrY0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c622fda4-f9f4-4fbd-db0d-53565b2fda84"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Size of new entity linked dataset: 9289\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_entities = 0\n",
        "for q, a in questions:\n",
        "  for word in q:\n",
        "    if \"<\" in word: n_entities += 1\n",
        "print(\"Average number of entities per query:\", round(n_entities / len(questions), 3))"
      ],
      "metadata": {
        "id": "SWclkmETfmHl",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bd503b1a-a3bb-4e54-c03b-d2c7eadd875a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Average number of entities per query: 1.231\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linked_q = []\n",
        "with open(\"/content/drive/MyDrive/dblp_heldout_500_questions.json\", 'r', encoding='utf-8') as file:\n",
        "  data = json.load(file)\n",
        "\n",
        "  for entry in data:\n",
        "    question = format_question(entry[\"question\"])\n",
        "    question, q_entities = process_question_entities(question)\n",
        "\n",
        "    paraphrased = format_question(entry[\"paraphrase\"])\n",
        "    paraphrased, p_entities = process_question_entities(paraphrased)\n",
        "\n",
        "    linked, entities = [], []\n",
        "    if len(q_entities) >= len(p_entities):\n",
        "      entities = q_entities\n",
        "      linked = question\n",
        "    else:\n",
        "      entities = p_entities\n",
        "      linked = paraphrased\n",
        "\n",
        "    _answer = {\n",
        "      'id': entry[\"id\"],\n",
        "      'question': entry[\"question\"],\n",
        "      'linked': linked,\n",
        "      'entities': entities,\n",
        "      'answer': [],\n",
        "    }\n",
        "    linked_q.append(_answer)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/dblp_linked_500_questions.json\", 'w', encoding='utf-8') as file:\n",
        "  json.dump(linked_q, file)\n",
        "\n",
        "len(linked_q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wRKZOgYnUlBG",
        "outputId": "b9069ca0-98d4-43f3-ba20-98c49aa8c029"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "500"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "linked_q = []\n",
        "with open(\"/content/drive/MyDrive/dblp_linked_500_questions.json\", 'r', encoding='utf-8') as file:\n",
        "  linked_q = json.load(file)"
      ],
      "metadata": {
        "id": "SbDtwRYmGLnL"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Encoding and decoding"
      ],
      "metadata": {
        "id": "ho5Acme5ul6F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Encoder\n",
        "text = [a['linked'] for a in linked_q]\n",
        "text += [a + \" \" + q for a, q in questions]\n",
        "words = list(set((\" \".join(text)).split(\" \")))\n",
        "words.append('¿') # Sequence init character\n",
        "words.append('¡') # Sequence end character\n",
        "words.append('<https://dblp.org/pid/27/4034-1>')\n",
        "words = sorted(words) # unique characters\n",
        "word_vocab_size = len(words) # amount of unique characters\n",
        "word_stoi = { w:i for i,w in enumerate(words) } # map char to int\n",
        "word_itos = { i:w for i,w in enumerate(words) } # map int to char\n",
        "word_encoder = lambda s: [word_stoi[w] for w in s.split(\" \")] # encoder\n",
        "word_decoder = lambda l: ' '.join([word_itos[i] for i in l]) # decoder\n",
        "print(\"Vocabulary size:\", len(words))"
      ],
      "metadata": {
        "id": "sHxKryviuoLj",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9296caf4-72c9-4eea-fb9b-ee06b9ddaccb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Vocabulary size: 10399\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "old_words = list(set((\" \".join([a + \" \" + q for a, q in questions])).split(\" \")))\n",
        "print(\"Old vocabulary size:\", len(old_words))\n",
        "entities = []\n",
        "for w in old_words:\n",
        "  if '<' in w and len(w) > 1: entities.append(w)\n",
        "print(\"Old number of entities:\",  len(entities))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElbwpBJlttTk",
        "outputId": "4d35001d-4f68-4204-f8ce-e0a407fc25f1"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Old vocabulary size: 9339\n",
            "Old number of entities: 7143\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "mN39KbQvRzz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# hyperparams\n",
        "batch_size = 32\n",
        "max_iters = 6000\n",
        "text_sample = max_iters // 6\n",
        "eval_interval = 200\n",
        "learning_rate = 7e-4\n",
        "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
        "eval_iters = 200\n",
        "n_embd = 128\n",
        "n_head = 8\n",
        "n_layer = 4\n",
        "\n",
        "class Head(nn.Module):\n",
        "    \"\"\" one head of self-attention \"\"\"\n",
        "\n",
        "    def __init__(self, head_size, b_size, masked=True):\n",
        "        super().__init__()\n",
        "        self.key = nn.Linear(n_embd, head_size, bias=False, device=device)\n",
        "        self.query = nn.Linear(n_embd, head_size, bias=False, device=device)\n",
        "        self.value = nn.Linear(n_embd, head_size, bias=False, device=device)\n",
        "        self.register_buffer('tril', torch.tril(torch.ones(b_size, b_size)))\n",
        "\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.masked = masked\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "        B,T,C = x.shape\n",
        "        q = self.query(x) # (B,T,C)\n",
        "        if y is None:\n",
        "          k = self.key(x)   # (B,T,C)\n",
        "        else:\n",
        "          k = self.key(y)\n",
        "        wei = q @ k.transpose(-2,-1) * C**-0.5 # (B, T, C) @ (B, C, T) -> (B, T, T)\n",
        "        if self.masked:\n",
        "          mask = self.tril[:T, :T] == 0\n",
        "          wei = wei.masked_fill(mask.to(device), float('-inf')) # (B, T, T)\n",
        "        wei = F.softmax(wei, dim=-1) # (B, T, T)\n",
        "        wei = self.dropout(wei)\n",
        "        if y is None:\n",
        "          v = self.value(x) # (B,T,C)\n",
        "        else:\n",
        "          v = self.value(y)\n",
        "        out = wei @ v # (B, T, T) @ (B, T, C) -> (B, T, C)\n",
        "        return out\n",
        "\n",
        "class MultiHeadAttention(nn.Module):\n",
        "    \"\"\" multiple heads of self-attention in parallel \"\"\"\n",
        "    def __init__(self, num_heads, head_size, b_size, masked=True):\n",
        "        super().__init__()\n",
        "        self.heads = nn.ModuleList([Head(head_size, b_size, masked) for _ in range(num_heads)])\n",
        "        self.proj = nn.Linear(n_embd, n_embd, device=device)\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "\n",
        "    def forward(self, x, y=None):\n",
        "      if y is None:\n",
        "        out = torch.cat([h(x) for h in self.heads], dim=-1)\n",
        "      else:\n",
        "        out = torch.cat([h(x, y) for h in self.heads], dim=-1)\n",
        "      out = self.dropout(self.proj(out))\n",
        "      return out\n",
        "\n",
        "class FeedFoward(nn.Module):\n",
        "    \"\"\" a simple linear layer followed by a non-linearity \"\"\"\n",
        "    def __init__(self, n_embd):\n",
        "        super().__init__()\n",
        "        self.net = nn.Sequential(\n",
        "            nn.Linear(n_embd, 4 * n_embd, device=device),\n",
        "            nn.ReLU(),\n",
        "            nn.Linear(4 * n_embd, n_embd, device=device),\n",
        "            nn.Dropout(dropout),\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        return self.net(x)\n",
        "\n",
        "class DecoderBlock(nn.Module):\n",
        "    \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "    def __init__(self, n_embd, n_head):\n",
        "        super().__init__()\n",
        "        head_size = n_embd // n_head\n",
        "\n",
        "        self.sa_decoder1 = MultiHeadAttention(n_head, head_size, MAX_OUT_BLOCK, masked=True)\n",
        "        self.sa_decoder2 = MultiHeadAttention(n_head, head_size, MAX_OUT_BLOCK, masked=False)\n",
        "        self.ffwd_decoder = FeedFoward(n_embd)\n",
        "        self.ln_decoder1 = nn.LayerNorm(n_embd, device=device)\n",
        "        self.ln_decoder2 = nn.LayerNorm(n_embd, device=device)\n",
        "        self.ln_decoder3 = nn.LayerNorm(n_embd, device=device)\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x = x + self.sa_decoder1(self.ln_decoder1(x))\n",
        "        x = x + self.sa_decoder2(self.ln_decoder2(x), y)\n",
        "        x = x + self.ffwd_decoder(self.ln_decoder3(x))\n",
        "        return x\n",
        "\n",
        "class EncoderBlock(nn.Module):\n",
        "  \"\"\" Transformer block: communication followed by computation \"\"\"\n",
        "  def __init__(self, n_embd, n_head):\n",
        "      super().__init__()\n",
        "      head_size = n_embd // n_head\n",
        "\n",
        "      self.sa_encoder = MultiHeadAttention(n_head, head_size, MAX_IN_BLOCK, masked=False)\n",
        "      self.ffwd_encoder = FeedFoward(n_embd)\n",
        "      self.ln_encoder1 = nn.LayerNorm(n_embd, device=device)\n",
        "      self.ln_encoder2 = nn.LayerNorm(n_embd, device=device)\n",
        "\n",
        "  def forward(self, x):\n",
        "      x = x + self.sa_encoder(self.ln_encoder1(x))\n",
        "      x = x + self.ffwd_encoder(self.ln_encoder2(x))\n",
        "      return x\n",
        "\n",
        "class TransformerModel(nn.Module):\n",
        "    def __init__(self, encoder_blocks, vocab_size):\n",
        "        super().__init__()\n",
        "        self.token_embedding_table = nn.Embedding(vocab_size, n_embd)\n",
        "        self.position_embedding_table = nn.Embedding(MAX_IN_BLOCK, n_embd)\n",
        "        self.position_embedding_table_dec = nn.Embedding(MAX_OUT_BLOCK, n_embd)\n",
        "        self.decoder_blocks = [DecoderBlock(n_embd, n_head) for _ in range(n_layer)]\n",
        "        self.encoder_blocks = encoder_blocks\n",
        "        self.ln_f = nn.LayerNorm(n_embd, device=device) # final layer norm\n",
        "        self.lm_head = nn.Linear(n_embd, vocab_size, device=device)\n",
        "\n",
        "    def forward(self, idx, idy, targets=None):\n",
        "        Bx, Tx = idx.shape\n",
        "        By, Ty = idy.shape\n",
        "        # Encoder\n",
        "        tok_emb_enc = self.token_embedding_table(idx) # (B,T,C)\n",
        "        pos_emb_enc = self.position_embedding_table(torch.arange(Tx, device=device)) # (T,C)\n",
        "        enc_x = tok_emb_enc + pos_emb_enc # (B,T,C)\n",
        "        enc_x = self.encoder_blocks(enc_x) # (B,T,C)\n",
        "        # Decoder\n",
        "        tok_emb = self.token_embedding_table(idy) # (B,T,C)\n",
        "        pos_emb = self.position_embedding_table_dec(torch.arange(Ty, device=device)) # (T,C)\n",
        "        x = tok_emb + pos_emb # (B,T,C)\n",
        "        for decoder_block in self.decoder_blocks:\n",
        "          x = decoder_block(x, enc_x) # (B,T,C)\n",
        "        x = self.ln_f(x) # (B,T,C)\n",
        "        logits = self.lm_head(x) # (B,T,vocab_size)\n",
        "\n",
        "        if targets is None:\n",
        "          loss = None\n",
        "        else:\n",
        "          B, T, C = logits.shape\n",
        "          logits = logits.view(B*T, C)\n",
        "          targets = targets.view(B*T)\n",
        "          loss = F.cross_entropy(logits, targets)\n",
        "        return logits, loss\n",
        "\n",
        "    def generate(self, idx, start_token_idx, max_new_tokens):\n",
        "      idy = torch.full((idx.size(0), 1), start_token_idx[0], dtype=torch.long, device=idx.device)\n",
        "\n",
        "      for _ in range(max_new_tokens):\n",
        "        # get the predictions\n",
        "        logits, _ = self(idx, idy)\n",
        "        # focus only on the last time step\n",
        "        logits = logits[:, -1, :] # becomes (B, C)\n",
        "        # apply softmax to get probabilities\n",
        "        probs = F.softmax(logits, dim=-1) # (B, C)\n",
        "        # sample from the distribution\n",
        "        idy_next = torch.multinomial(probs, num_samples=1) # (B, 1)\n",
        "        # append sampled index to the running sequence\n",
        "        idy = torch.cat((idy, idy_next), dim=1) # (B, T+1)\n",
        "      return idy\n",
        "\n",
        "    def save(self, path, optimizer):\n",
        "      torch.save({\n",
        "          'state_dict': self.state_dict(),\n",
        "          'optimizer': optimizer.state_dict()\n",
        "      }, path)\n",
        "\n",
        "    def load(self, checkpoint_path, optimizer):\n",
        "      checkpoint = torch.load(checkpoint_path)\n",
        "      self.load_state_dict(checkpoint['state_dict'])\n",
        "      optimizer.load_state_dict(checkpoint['optimizer'])"
      ],
      "metadata": {
        "id": "jDQ_sp1MmAXw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Split data and loss estimation"
      ],
      "metadata": {
        "id": "aonNM0sL440h"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def split_and_encode_text(input_array, encoder):\n",
        "  result = []\n",
        "  max_in_block = -1\n",
        "  max_out_block = -1\n",
        "  shuffle(input_array)\n",
        "  for item in input_array:\n",
        "    in_task = torch.tensor(encoder(item[0]), dtype=torch.long)\n",
        "    out_task = torch.tensor(encoder(item[1]), dtype=torch.long)\n",
        "    result.append((in_task, out_task))\n",
        "\n",
        "    len_in_block = len(in_task)\n",
        "    len_out_block = len(out_task)\n",
        "\n",
        "    if max_in_block < len_in_block: max_in_block = len_in_block\n",
        "    if max_out_block < len_out_block: max_out_block = len_out_block\n",
        "\n",
        "  return result, max_in_block + 1, max_out_block + 1"
      ],
      "metadata": {
        "id": "JZQ8Qbjr49u-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Split vectorized data\n",
        "data, MAX_IN_BLOCK, MAX_OUT_BLOCK = split_and_encode_text(questions, word_encoder)\n",
        "\n",
        "entities = []\n",
        "for w in words:\n",
        "  if '<' in w and len(w) > 1: entities.append(w)\n",
        "print(\"Pretrain data size:\",  len(entities))\n",
        "entities = [(\" \".join([e]*MAX_IN_BLOCK), \" \".join([e]*MAX_OUT_BLOCK)) for e in entities]\n",
        "\n",
        "data_pre, MAX_IN_BLOCK_pre, MAX_OUT_BLOCx_pre = split_and_encode_text(entities, word_encoder)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C9roXVnVEyoc",
        "outputId": "3ecbbece-36f6-4e75-bf5f-fc2892f270e9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Pretrain data size: 7617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Auxiliary train and test methods"
      ],
      "metadata": {
        "id": "9HBDU2sOuaQH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "@torch.no_grad()\n",
        "def estimate_loss():\n",
        "  out = {}\n",
        "  m.eval()\n",
        "  for split in ['train', 'val']:\n",
        "    losses = torch.zeros(eval_iters)\n",
        "    for k in range(eval_iters):\n",
        "      X, Y, targets = get_batch(split, word_encoder)\n",
        "      logits, loss = m(X, Y, targets)\n",
        "      losses[k] = loss.item()\n",
        "    out[split] = losses.mean()\n",
        "  m.train()\n",
        "  return out\n",
        "\n",
        "def get_batch(split, encoder):\n",
        "    data = train_data if split == 'train' else val_data # elige un dataset dependiendo de la etapa\n",
        "    ix = torch.randint(len(data)-1, (batch_size,))\n",
        "    batch = [data[i] for i in ix]\n",
        "    start_token = torch.tensor(encoder('¿'))\n",
        "    end_token = torch.tensor(encoder('¡'))\n",
        "    x = torch.stack([F.pad(in_v, (0, MAX_IN_BLOCK - len(in_v)), value=1) for (in_v, _) in batch])\n",
        "    y = torch.stack([F.pad(torch.cat([start_token, out_v]), (0, MAX_OUT_BLOCK - len(out_v) - 1), value=1) for (_, out_v) in batch])\n",
        "    t = torch.stack([F.pad(torch.cat([out_v, end_token]), (0, MAX_OUT_BLOCK - len(out_v) - 1), value=1) for (_, out_v) in batch])\n",
        "    x, y, t = x.to(device), y.to(device), t.to(device)\n",
        "    return x, y, t\n",
        "\n",
        "def train_model(m, estimate_loss, optimizer, encoder, decoder):\n",
        "  intermediate_prints = []\n",
        "  for iter in range(max_iters):\n",
        "    # every once in a while evaluate the loss on train and val sets\n",
        "    if iter % eval_interval == 0 or iter == max_iters - 1:\n",
        "      losses = estimate_loss()\n",
        "      print(f\"step {iter}: train loss {losses['train']:.4f}, val loss {losses['val']:.4f}\")\n",
        "\n",
        "    # sample a batch of data\n",
        "    xb, yb, targets = get_batch('train', encoder)\n",
        "\n",
        "    # evaluate the loss\n",
        "    logits, loss = m(xb, yb, targets)\n",
        "    optimizer.zero_grad(set_to_none=True)\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if iter % text_sample == 0 or iter == max_iters - 1:\n",
        "      input_tokens = torch.zeros((1, 1), dtype=torch.long)\n",
        "      xb, yb, targets = get_batch('val', encoder)\n",
        "      m.eval()\n",
        "      intermediate_prints.append(decoder(m.generate(xb, encoder('¿'), MAX_OUT_BLOCK)[0].tolist()))\n",
        "      m.train()\n",
        "    del xb\n",
        "    del yb\n",
        "    del targets\n",
        "\n",
        "  return intermediate_prints\n",
        "\n",
        "def test_model(samples, m, encoder, decoder, test_data):\n",
        "  one_shot_hits = 0\n",
        "  three_shot_hits = 0\n",
        "  hamming_distance = 0\n",
        "  m.eval()\n",
        "  for i, test in enumerate(test_data[:samples]):\n",
        "    if i % 20 == 0: print(\"Sample: \", str(i))\n",
        "    in_t, out_t = test\n",
        "    n_tokens = len(out_t)\n",
        "    padded_text = F.pad(in_t, (0, MAX_IN_BLOCK - len(in_t)), value=1)\n",
        "\n",
        "    misses = 0\n",
        "    out_list = out_t.tolist()\n",
        "    shot = m.generate(padded_text.unsqueeze(0).to(device), encoder('¿'), n_tokens)[0].tolist()[1:]\n",
        "    for a,b in zip(shot, out_list):\n",
        "      if a != b: misses += 1\n",
        "\n",
        "    if misses:\n",
        "      hamming_distance += misses\n",
        "      hit = False\n",
        "      for _ in range(2):\n",
        "        shot = m.generate(padded_text.unsqueeze(0).to(device), encoder('¿'), n_tokens)[0].tolist()[1:]\n",
        "        if shot == out_list: hit = True\n",
        "      if hit: three_shot_hits += 1\n",
        "    else:\n",
        "      one_shot_hits += 1\n",
        "      three_shot_hits += 1\n",
        "\n",
        "\n",
        "  acc1 = round(one_shot_hits / samples, 5)\n",
        "  acc3 = round(three_shot_hits / samples, 5)\n",
        "  mhd = round(hamming_distance / samples, 5)\n",
        "  m.train()\n",
        "  return acc1, acc3, mhd"
      ],
      "metadata": {
        "id": "I1ti2yCIuZ0K"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model with pretrain"
      ],
      "metadata": {
        "id": "Qo1VQXN9xE1r"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Pretrain"
      ],
      "metadata": {
        "id": "jMHlz6sNxWCj"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment hyperparams\n",
        "dropout = 0.01\n",
        "split = 1\n",
        "\n",
        "# Data division\n",
        "n_test = int(len(data_pre))\n",
        "test_data = data_pre\n",
        "print(\"Test cases train:\", n_test)\n",
        "\n",
        "n_train = int(len(data_pre))\n",
        "print(\"Train cases:\", n_train)\n",
        "train_data = data_pre\n",
        "val_data = data_pre\n",
        "print(\"Validation cases:\", len(val_data))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BHRuAyLPG1Xn",
        "outputId": "b01c2d0f-c0d3-4021-a99e-df2a8d58c104"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test cases train: 7617\n",
            "Train cases: 7617\n",
            "Validation cases: 7617\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Model init\n",
        "encoder_blocks = nn.Sequential(*[EncoderBlock(n_embd, n_head) for _ in range(n_layer)])\n",
        "full_model = TransformerModel(encoder_blocks, word_vocab_size)\n",
        "m = full_model.to(device)\n",
        "\n",
        "# Print init loss and hyperparams\n",
        "x1, y1, targets = get_batch('train', word_encoder)\n",
        "print(\"Device:\", device)\n",
        "logits, loss = m(x1, y1, targets)\n",
        "print(logits.shape)\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# Instanciar optimizador\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "id": "0J-nCaN2l6rN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "056d01b9-92ee-45e3-b9a3-38ea7c366200"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "torch.Size([1568, 10399])\n",
            "Loss: tensor(9.3208, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3.474975 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 14400\n",
        "text_sample = max_iters // 6\n",
        "intermediate_prints = train_model(m, estimate_loss, optimizer, word_encoder, word_decoder)\n",
        "\n",
        "for idx, intermediate_print in enumerate(intermediate_prints):\n",
        "  print(\"Sample {}:\\n\".format(idx), intermediate_print)\n",
        "\n",
        "m.save(\"/content/drive/MyDrive/transformer-pretrain-final.pth\", optimizer)"
      ],
      "metadata": {
        "id": "YrPxXbwP5l0c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "79ae61e7-a38d-40f0-a941-0a23addc6875"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 9.4087, val loss 9.4129\n",
            "step 200: train loss 8.8382, val loss 8.8434\n",
            "step 400: train loss 8.0246, val loss 8.0579\n",
            "step 600: train loss 7.0254, val loss 7.0388\n",
            "step 800: train loss 5.7848, val loss 5.7535\n",
            "step 1000: train loss 4.3185, val loss 4.3537\n",
            "step 1200: train loss 2.9968, val loss 2.9963\n",
            "step 1400: train loss 1.9129, val loss 1.8723\n",
            "step 1600: train loss 1.1284, val loss 1.1320\n",
            "step 1800: train loss 0.5990, val loss 0.6161\n",
            "step 2000: train loss 0.3469, val loss 0.3598\n",
            "step 2200: train loss 0.1924, val loss 0.2017\n",
            "step 2400: train loss 0.1050, val loss 0.1294\n",
            "step 2600: train loss 0.0854, val loss 0.0748\n",
            "step 2800: train loss 0.0480, val loss 0.0459\n",
            "step 3000: train loss 0.0344, val loss 0.0365\n",
            "step 3200: train loss 0.0231, val loss 0.0240\n",
            "step 3400: train loss 0.0183, val loss 0.0194\n",
            "step 3600: train loss 0.0145, val loss 0.0152\n",
            "step 3800: train loss 0.0123, val loss 0.0126\n",
            "step 4000: train loss 0.0106, val loss 0.0106\n",
            "step 4200: train loss 0.0093, val loss 0.0092\n",
            "step 4400: train loss 0.0081, val loss 0.0080\n",
            "step 4600: train loss 0.0070, val loss 0.0071\n",
            "step 4800: train loss 0.0063, val loss 0.0063\n",
            "step 5000: train loss 0.0055, val loss 0.0056\n",
            "step 5200: train loss 0.0049, val loss 0.0049\n",
            "step 5400: train loss 0.0044, val loss 0.0044\n",
            "step 5600: train loss 0.0040, val loss 0.0039\n",
            "step 5800: train loss 0.0035, val loss 0.0035\n",
            "step 6000: train loss 0.0032, val loss 0.0032\n",
            "step 6200: train loss 0.0028, val loss 0.0028\n",
            "step 6400: train loss 0.0025, val loss 0.0025\n",
            "step 6600: train loss 0.0023, val loss 0.0022\n",
            "step 6800: train loss 0.0020, val loss 0.0021\n",
            "step 7000: train loss 0.0018, val loss 0.0018\n",
            "step 7200: train loss 0.0016, val loss 0.0016\n",
            "step 7400: train loss 0.0015, val loss 0.0015\n",
            "step 7600: train loss 0.0013, val loss 0.0013\n",
            "step 7800: train loss 0.0012, val loss 0.0012\n",
            "step 8000: train loss 0.0011, val loss 0.0011\n",
            "step 8200: train loss 0.0010, val loss 0.0010\n",
            "step 8400: train loss 0.0009, val loss 0.0009\n",
            "step 8600: train loss 0.0008, val loss 0.0008\n",
            "step 8800: train loss 0.0007, val loss 0.0007\n",
            "step 9000: train loss 0.0006, val loss 0.0006\n",
            "step 9200: train loss 0.0006, val loss 0.0006\n",
            "step 9400: train loss 0.0005, val loss 0.0005\n",
            "step 9600: train loss 0.0005, val loss 0.0005\n",
            "step 9800: train loss 0.0004, val loss 0.0004\n",
            "step 10000: train loss 0.0004, val loss 0.0004\n",
            "step 10200: train loss 0.0003, val loss 0.0003\n",
            "step 10400: train loss 0.0003, val loss 0.0003\n",
            "step 10600: train loss 0.0003, val loss 0.0003\n",
            "step 10800: train loss 0.0002, val loss 0.0002\n",
            "step 11000: train loss 0.0002, val loss 0.0002\n",
            "step 11200: train loss 0.0002, val loss 0.0002\n",
            "step 11400: train loss 0.0002, val loss 0.0002\n",
            "step 11600: train loss 0.0002, val loss 0.0002\n",
            "step 11800: train loss 0.0001, val loss 0.0001\n",
            "step 12000: train loss 0.0001, val loss 0.0001\n",
            "step 12200: train loss 0.0001, val loss 0.0001\n",
            "step 12400: train loss 0.0001, val loss 0.0001\n",
            "step 12600: train loss 0.0001, val loss 0.0001\n",
            "step 12800: train loss 0.0001, val loss 0.0001\n",
            "step 13000: train loss 0.0001, val loss 0.0001\n",
            "step 13200: train loss 0.0001, val loss 0.0001\n",
            "step 13400: train loss 0.0001, val loss 0.0001\n",
            "step 13600: train loss 0.0001, val loss 0.0001\n",
            "step 13800: train loss 0.0001, val loss 0.0001\n",
            "step 14000: train loss 0.0000, val loss 0.0000\n",
            "step 14200: train loss 0.0000, val loss 0.0000\n",
            "step 14399: train loss 0.0000, val loss 0.0000\n",
            "Sample 0:\n",
            " ¿ <https://dblp.org/rec/conf/icra/WalterBLA04> <https://dblp.org/pid/21/7459> <https://dblp.org/rec/journals/pr/AneesC18> <https://dblp.org/pid/82/1415> <https://dblp.org/rec/journals/ieeejas/Zhang18> <https://dblp.org/pid/43/5210> <https://dblp.org/pid/73/7523> <https://dblp.org/pid/300/1951> Sens., <https://dblp.org/pid/95/4944> 'COMPSAC' <https://dblp.org/rec/conf/colt/MendelsonP05> <https://dblp.org/pid/153/6258> <https://dblp.org/pid/276/3533> Real <https://dblp.org/rec/conf/aughuman/ElagroudyF022> <https://dblp.org/pid/164/8296> <https://dblp.org/rec/conf/simulationstechnik/Stahel87> <https://dblp.org/rec/journals/jco/JinKLW06> <https://dblp.org/pid/58/2943> has <https://dblp.org/rec/journals/tpds/Sanzo17> <https://dblp.org/rec/conf/isda/YiLW06> 5 <https://dblp.org/pid/44/10155> <https://dblp.org/pid/221/8670> <https://dblp.org/rec/conf/ices/ZhaoDLP07> <https://dblp.org/rec/journals/monet/AgarwalJFYG07> <https://dblp.org/rec/journals/cm/Bahl98> Association <https://dblp.org/rec/journals/dmgt/LiS13> <https://dblp.org/rec/journals/corr/abs-2206-05208>, 'ITNAC' <https://dblp.org/rec/journals/dm/BouyuklievKM15> <https://dblp.org/pid/26/1626> 'ISPRS John <https://dblp.org/pid/141/8912> <https://dblp.org/rec/conf/ijcnn/YehCJH15> <https://dblp.org/pid/44/849> <https://dblp.org/rec/journals/spl/Pham04> 'Eur. <https://dblp.org/pid/34/2415> <https://dblp.org/pid/69/10440> <https://dblp.org/rec/journals/spacecomm/BauerKIK02>, Optimization <https://dblp.org/rec/journals/access/LuoS20> <https://dblp.org/rec/conf/ictc/KimL21a> <https://dblp.org/pid/119/5768>\n",
            "Sample 1:\n",
            " ¿ <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/23/8131> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/194/5506> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/rec/conf/spire/CastilloDG07> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117> <https://dblp.org/pid/88/2117>\n",
            "Sample 2:\n",
            " ¿ <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09> <https://dblp.org/rec/conf/ncm/HangF09>\n",
            "Sample 3:\n",
            " ¿ <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276> <https://dblp.org/pid/47/3276>\n",
            "Sample 4:\n",
            " ¿ <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785> <https://dblp.org/pid/32/6785>\n",
            "Sample 5:\n",
            " ¿ <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945> <https://dblp.org/pid/187/9945>\n",
            "Sample 6:\n",
            " ¿ <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464> <https://dblp.org/pid/08/464>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc1, acc3, mhd = test_model(200, m, word_encoder, word_decoder, test_data)\n",
        "print('Accuracy@1 on test: {}%'.format(acc1 * 100))\n",
        "print('Accuracy@3 on test: {}%'.format(acc3 * 100))\n",
        "print('Mean Hamming distance on test: {}'.format(mhd))"
      ],
      "metadata": {
        "id": "nTfqLmKYrvug",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "dd9ae436-2512-41a1-b1df-2a89b3bf8b0d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:  0\n",
            "Sample:  20\n",
            "Sample:  40\n",
            "Sample:  60\n",
            "Sample:  80\n",
            "Sample:  100\n",
            "Sample:  120\n",
            "Sample:  140\n",
            "Sample:  160\n",
            "Sample:  180\n",
            "Accuracy@1 on test: 99.5%\n",
            "Accuracy@3 on test: 100.0%\n",
            "Mean Hamming distance on test: 0.005\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "kCk-VWYexfWL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Experiment hyperparams\n",
        "dropout = 0.01\n",
        "split = 0.95\n",
        "\n",
        "# Data division\n",
        "n_test = int(0.02*len(data))\n",
        "test_data = data[:n_test]\n",
        "print(\"Test cases train:\", n_test)\n",
        "\n",
        "data = data[n_test:]\n",
        "n_train = int(split*len(data))\n",
        "print(\"Train cases:\", n_train)\n",
        "train_data = data[:n_train]\n",
        "val_data = data[n_train:]\n",
        "print(\"Validation cases:\", len(val_data))"
      ],
      "metadata": {
        "id": "LAKfJtuUID81",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f2827df1-fd8c-4ae9-8a6e-ecebc3c43fcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test cases train: 185\n",
            "Train cases: 8648\n",
            "Validation cases: 456\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 4800\n",
        "text_sample = max_iters // 6\n",
        "\n",
        "intermediate_prints = train_model(m, estimate_loss, optimizer, word_encoder, word_decoder)\n",
        "\n",
        "for idx, intermediate_print in enumerate(intermediate_prints):\n",
        "  print(\"Sample {}:\\n\".format(idx), intermediate_print)"
      ],
      "metadata": {
        "id": "lIIuPgGOJQ1B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "82303f31-c894-40e3-811c-37de1e3b9608"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 13.5342, val loss 13.5327\n",
            "step 200: train loss 0.7309, val loss 0.8128\n",
            "step 400: train loss 0.3958, val loss 0.5117\n",
            "step 600: train loss 0.2311, val loss 0.3818\n",
            "step 800: train loss 0.1507, val loss 0.3148\n",
            "step 1000: train loss 0.0951, val loss 0.2639\n",
            "step 1200: train loss 0.0708, val loss 0.2352\n",
            "step 1400: train loss 0.0490, val loss 0.2083\n",
            "step 1600: train loss 0.0378, val loss 0.2050\n",
            "step 1800: train loss 0.0300, val loss 0.1912\n",
            "step 2000: train loss 0.0218, val loss 0.1894\n",
            "step 2200: train loss 0.0191, val loss 0.1848\n",
            "step 2400: train loss 0.0147, val loss 0.1751\n",
            "step 2600: train loss 0.0107, val loss 0.1802\n",
            "step 2800: train loss 0.0092, val loss 0.1843\n",
            "step 3000: train loss 0.0079, val loss 0.1762\n",
            "step 3200: train loss 0.0070, val loss 0.1765\n",
            "step 3400: train loss 0.0064, val loss 0.1728\n",
            "step 3600: train loss 0.0060, val loss 0.1776\n",
            "step 3800: train loss 0.0048, val loss 0.1688\n",
            "step 4000: train loss 0.0037, val loss 0.1756\n",
            "step 4200: train loss 0.0038, val loss 0.1659\n",
            "step 4400: train loss 0.0039, val loss 0.1807\n",
            "step 4600: train loss 0.0035, val loss 0.1718\n",
            "step 4799: train loss 0.0043, val loss 0.1811\n",
            "Sample 0:\n",
            " ¿ <https://dblp.org/rec/conf/ACMace/LundCW11> <https://dblp.org/rec/conf/igarss/MasekJRSCD18> <https://dblp.org/rec/conf/cdc/ZhaoB03a> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/pid/17/8309> <https://dblp.org/rec/conf/wifs/ChenABD12> <https://dblp.org/rec/journals/corr/YuanG15> <https://dblp.org/pid/70/8831> <https://dblp.org/rec/conf/wifs/ChenABD12> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/pid/123/8868> <https://dblp.org/rec/conf/isscc/LiangBW08> <https://dblp.org/rec/journals/ijwin/Kim01>, <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/pid/255/0265> <https://dblp.org/rec/conf/iros/SawadaM03> <https://dblp.org/rec/conf/iros/SawadaM03> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/conf/ever/SchwimmbeckBH20> <https://dblp.org/rec/conf/uml/DeublerMRK05> <https://dblp.org/rec/journals/talg/AnnamalaiKS17> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/conf/icwsm/ChengDL14> <https://dblp.org/rec/journals/hmd/Soutschek10> <https://dblp.org/rec/journals/corr/abs-1803-11359>\n",
            "Sample 1:\n",
            " ¿ SELECT DISTINCT ( COUNT( ?answer ) AS ?count ) WHERE { <https://dblp.org/rec/conf/icccsec/WangQJG21> <https://dblp.org/rdf/schema#authoredBy> ?x . ?answer <https://dblp.org/rdf/schema#authoredBy> ?x . ?answer <https://dblp.org/rdf/schema#yearOfPublication> '2017' } ¡ <https://dblp.org/rdf/schema#yearOfPublication> ?y } ¡ . ?x <https://dblp.org/rdf/schema#authoredBy> ?x . ?answer <https://dblp.org/rdf/schema#authoredBy> ?x } ¡ <https://dblp.org/rdf/schema#authoredBy> ?x } ¡ <https://dblp.org/rdf/schema#yearOfPublication> '2019' } ¡ } ¡ }\n",
            "Sample 2:\n",
            " ¿ SELECT ( COUNT( DISTINCT ?answer ) AS ?count ) WHERE { <https://dblp.org/rec/journals/comcom/BraunGS04> <https://dblp.org/rdf/schema#authoredBy> ?x . ?x <https://dblp.org/rdf/schema#primaryAffiliation> ?answer } ¡ } ¡ } ¡ <https://dblp.org/rdf/schema#authoredBy> ?x <https://dblp.org/rdf/schema#authoredBy> ?x . ?x <https://dblp.org/rdf/schema#primaryAffiliation> ?answer } ¡ <https://dblp.org/rdf/schema#primaryAffiliation> ?answer } ¡ } ¡ } ¡ != != != != != != !=\n",
            "Sample 3:\n",
            " ¿ ASK { <https://dblp.org/rec/journals/ijbdcn/ChandnaniKS17> <https://dblp.org/rdf/schema#authoredBy> ?x . ?y <https://dblp.org/rdf/schema#authoredBy> ?x FILTER ( ?y != <https://dblp.org/rec/journals/zmp/KimT18> ) . ?y <https://dblp.org/rdf/schema#publishedIn> 'J. Adv. )' FILTER NOT EXISTS { <https://dblp.org/rec/journals/ijwmip/GuoO09> <https://dblp.org/rdf/schema#authoredBy> ?x . ?y <https://dblp.org/rdf/schema#publishedIn> 'J. Intell. Fuzzy != != != != != != != != != != != != != != !=\n",
            "Sample 4:\n",
            " ¿ SELECT ( GROUP_CONCAT( ?answer; separator=', ' ) AS ?answer ) ?count WHERE { SELECT DISTINCT ?answer ( COUNT( ?answer ) AS ?count ) WHERE { ?x <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/31/6907> . ?x <https://dblp.org/rdf/schema#yearOfPublication> ?answer } GROUP BY ?answer } ORDER BY DESC( ?count ) LIMIT 1 ¡ } ORDER BY DESC(\n",
            "Sample 5:\n",
            " ¿ SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/igarss/MrozBLTS18> <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/189/3448> . <https://dblp.org/rec/conf/igarss/MrozBLTS18> <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ } ¡ <https://dblp.org/rdf/schema#publishedIn> != != !=\n",
            "Sample 6:\n",
            " ¿ SELECT ( COUNT( DISTINCT ?answer ) AS ?count ) WHERE { ?answer <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/h/CarlHewitt> } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "m.save(\"/content/drive/MyDrive/transformer-pretrained-final.pth\", optimizer)"
      ],
      "metadata": {
        "id": "BMcWCDqZjq9Z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc1, acc3, mhd = test_model(n_test, m, word_encoder, word_decoder, test_data)\n",
        "print('Accuracy@1 on test: {}%'.format(acc1 * 100))\n",
        "print('Accuracy@3 on test: {}%'.format(acc3 * 100))\n",
        "print('Mean Hamming distance on test: {}'.format(mhd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YCZUt4AmVIn1",
        "outputId": "778e81da-b8a6-4aae-c98b-a9713bca6977"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:  0\n",
            "Sample:  20\n",
            "Sample:  40\n",
            "Sample:  60\n",
            "Sample:  80\n",
            "Sample:  100\n",
            "Sample:  120\n",
            "Sample:  140\n",
            "Sample:  160\n",
            "Sample:  180\n",
            "Accuracy@1 on test: 49.189%\n",
            "Accuracy@3 on test: 62.702999999999996%\n",
            "Mean Hamming distance on test: 2.01081\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_queries = []\n",
        "for entry in linked_q:\n",
        "  n_tokens = MAX_OUT_BLOCK\n",
        "  in_t = torch.tensor(word_encoder(entry[\"linked\"]), dtype=torch.long)\n",
        "  padded_text = F.pad(in_t, (0, MAX_IN_BLOCK - len(in_t)), value=1)\n",
        "  query = word_decoder(m.generate(padded_text.unsqueeze(0).to(device), word_encoder('¿'), n_tokens)[0].tolist()[1:])\n",
        "  query = query.split(\"¡\")[0]\n",
        "  entry[\"sparql\"] = query\n",
        "  final_queries.append(entry)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/dblp_pretrained_queries_500.json\", 'w', encoding='utf-8') as file:\n",
        "  json.dump(final_queries, file)"
      ],
      "metadata": {
        "id": "OysVKdniVYjn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model without pretrain"
      ],
      "metadata": {
        "id": "VRQzgqrKI1Xz"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Train"
      ],
      "metadata": {
        "id": "Q8u8ScBFxjGK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Model init\n",
        "encoder_blocks = nn.Sequential(*[EncoderBlock(n_embd, n_head) for _ in range(n_layer)])\n",
        "full_model = TransformerModel(encoder_blocks, word_vocab_size)\n",
        "m = full_model.to(device)\n",
        "\n",
        "# Print init loss and hyperparams\n",
        "x1, y1, targets = get_batch('train', word_encoder)\n",
        "print(\"Device:\", device)\n",
        "logits, loss = m(x1, y1, targets)\n",
        "print(logits.shape)\n",
        "print(\"Loss:\", loss)\n",
        "\n",
        "print(sum(p.numel() for p in m.parameters())/1e6, 'M parameters')\n",
        "\n",
        "# Instanciar optimizador\n",
        "optimizer = torch.optim.AdamW(m.parameters(), lr=learning_rate)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ElrdMLO01G29",
        "outputId": "ac54c220-1be6-4174-fb84-618d0e7d2de9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Device: cuda\n",
            "torch.Size([1568, 10399])\n",
            "Loss: tensor(9.1485, device='cuda:0', grad_fn=<NllLossBackward0>)\n",
            "3.474975 M parameters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "max_iters = 19200\n",
        "text_sample = max_iters // 6\n",
        "intermediate_prints = train_model(m, estimate_loss, optimizer, word_encoder, word_decoder)\n",
        "\n",
        "for idx, intermediate_print in enumerate(intermediate_prints):\n",
        "  print(\"Sample {}:\\n\".format(idx), intermediate_print)\n",
        "\n",
        "m.save(\"/content/drive/MyDrive/transformer-final.pth\", optimizer)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NAC9SR_x1L9Y",
        "outputId": "9c27c037-c749-44cc-a3ec-6744c2c663c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "step 0: train loss 9.1270, val loss 9.1256\n",
            "step 200: train loss 1.1205, val loss 1.1495\n",
            "step 400: train loss 0.6651, val loss 0.7350\n",
            "step 600: train loss 0.4713, val loss 0.5500\n",
            "step 800: train loss 0.3828, val loss 0.4890\n",
            "step 1000: train loss 0.3221, val loss 0.4391\n",
            "step 1200: train loss 0.2912, val loss 0.4207\n",
            "step 1400: train loss 0.2626, val loss 0.4134\n",
            "step 1600: train loss 0.2433, val loss 0.4012\n",
            "step 1800: train loss 0.2249, val loss 0.3964\n",
            "step 2000: train loss 0.2096, val loss 0.3790\n",
            "step 2200: train loss 0.1980, val loss 0.3821\n",
            "step 2400: train loss 0.1818, val loss 0.3615\n",
            "step 2600: train loss 0.1642, val loss 0.3618\n",
            "step 2800: train loss 0.1465, val loss 0.3632\n",
            "step 3000: train loss 0.1336, val loss 0.3605\n",
            "step 3200: train loss 0.1155, val loss 0.3533\n",
            "step 3400: train loss 0.1019, val loss 0.3400\n",
            "step 3600: train loss 0.0837, val loss 0.3427\n",
            "step 3800: train loss 0.0709, val loss 0.3281\n",
            "step 4000: train loss 0.0568, val loss 0.3261\n",
            "step 4200: train loss 0.0470, val loss 0.3245\n",
            "step 4400: train loss 0.0374, val loss 0.3136\n",
            "step 4600: train loss 0.0290, val loss 0.3107\n",
            "step 4800: train loss 0.0236, val loss 0.3095\n",
            "step 5000: train loss 0.0177, val loss 0.3133\n",
            "step 5200: train loss 0.0140, val loss 0.3099\n",
            "step 5400: train loss 0.0112, val loss 0.2918\n",
            "step 5600: train loss 0.0086, val loss 0.3114\n",
            "step 5800: train loss 0.0074, val loss 0.2981\n",
            "step 6000: train loss 0.0057, val loss 0.2895\n",
            "step 6200: train loss 0.0047, val loss 0.2935\n",
            "step 6400: train loss 0.0045, val loss 0.3115\n",
            "step 6600: train loss 0.0038, val loss 0.2855\n",
            "step 6800: train loss 0.0045, val loss 0.2880\n",
            "step 7000: train loss 0.0032, val loss 0.2991\n",
            "step 7200: train loss 0.0025, val loss 0.3105\n",
            "step 7400: train loss 0.0036, val loss 0.3032\n",
            "step 7600: train loss 0.0063, val loss 0.3103\n",
            "step 7800: train loss 0.0048, val loss 0.3099\n",
            "step 8000: train loss 0.0025, val loss 0.3213\n",
            "step 8200: train loss 0.0014, val loss 0.3072\n",
            "step 8400: train loss 0.0008, val loss 0.2932\n",
            "step 8600: train loss 0.0014, val loss 0.3072\n",
            "step 8800: train loss 0.0011, val loss 0.3171\n",
            "step 9000: train loss 0.0048, val loss 0.3295\n",
            "step 9200: train loss 0.0053, val loss 0.3194\n",
            "step 9400: train loss 0.0030, val loss 0.3119\n",
            "step 9600: train loss 0.0024, val loss 0.3069\n",
            "step 9800: train loss 0.0015, val loss 0.3137\n",
            "step 10000: train loss 0.0017, val loss 0.3058\n",
            "step 10200: train loss 0.0013, val loss 0.3108\n",
            "step 10400: train loss 0.0040, val loss 0.3328\n",
            "step 10600: train loss 0.0014, val loss 0.3215\n",
            "step 10800: train loss 0.0022, val loss 0.3059\n",
            "step 11000: train loss 0.0028, val loss 0.3288\n",
            "step 11200: train loss 0.0036, val loss 0.3417\n",
            "step 11400: train loss 0.0012, val loss 0.3222\n",
            "step 11600: train loss 0.0005, val loss 0.3036\n",
            "step 11800: train loss 0.0004, val loss 0.3056\n",
            "step 12000: train loss 0.0003, val loss 0.3043\n",
            "step 12200: train loss 0.0002, val loss 0.3010\n",
            "step 12400: train loss 0.0005, val loss 0.3061\n",
            "step 12600: train loss 0.0005, val loss 0.3140\n",
            "step 12800: train loss 0.0015, val loss 0.3301\n",
            "step 13000: train loss 0.0045, val loss 0.3534\n",
            "step 13200: train loss 0.0019, val loss 0.3237\n",
            "step 13400: train loss 0.0023, val loss 0.3266\n",
            "step 13600: train loss 0.0009, val loss 0.3179\n",
            "step 13800: train loss 0.0010, val loss 0.3211\n",
            "step 14000: train loss 0.0003, val loss 0.3275\n",
            "step 14200: train loss 0.0010, val loss 0.3273\n",
            "step 14400: train loss 0.0017, val loss 0.3243\n",
            "step 14600: train loss 0.0007, val loss 0.3214\n",
            "step 14800: train loss 0.0008, val loss 0.3337\n",
            "step 15000: train loss 0.0026, val loss 0.3541\n",
            "step 15200: train loss 0.0014, val loss 0.3179\n",
            "step 15400: train loss 0.0017, val loss 0.3298\n",
            "step 15600: train loss 0.0013, val loss 0.3045\n",
            "step 15800: train loss 0.0008, val loss 0.3079\n",
            "step 16000: train loss 0.0011, val loss 0.3212\n",
            "step 16200: train loss 0.0013, val loss 0.3313\n",
            "step 16400: train loss 0.0006, val loss 0.3151\n",
            "step 16600: train loss 0.0002, val loss 0.3251\n",
            "step 16800: train loss 0.0007, val loss 0.3226\n",
            "step 17000: train loss 0.0002, val loss 0.3244\n",
            "step 17200: train loss 0.0004, val loss 0.3222\n",
            "step 17400: train loss 0.0014, val loss 0.3385\n",
            "step 17600: train loss 0.0008, val loss 0.3035\n",
            "step 17800: train loss 0.0013, val loss 0.3372\n",
            "step 18000: train loss 0.0094, val loss 0.3700\n",
            "step 18200: train loss 0.0010, val loss 0.3239\n",
            "step 18400: train loss 0.0015, val loss 0.3435\n",
            "step 18600: train loss 0.0008, val loss 0.2990\n",
            "step 18800: train loss 0.0004, val loss 0.3014\n",
            "step 19000: train loss 0.0003, val loss 0.3180\n",
            "step 19199: train loss 0.0025, val loss 0.3476\n",
            "Sample 0:\n",
            " ¿ <https://dblp.org/pid/28/5745> 'EUSIPCO' <https://dblp.org/rec/conf/iwqos/BijarboonehFNP13> <https://dblp.org/rec/conf/ruleml/ZahariaVB08> <https://dblp.org/rec/journals/sensors/BadawiLE21> <https://dblp.org/rec/conf/ijcai/WangLZ13> <https://dblp.org/pid/61/3613> <https://dblp.org/rec/conf/isda/JiLX06> <https://dblp.org/rec/conf/winsys/VieiraMC16> <https://dblp.org/rec/conf/icmcs/ZengLWB10>, <https://dblp.org/rec/conf/isit/FujitaIY20> SIGFIDET <https://dblp.org/pid/314/9396> <https://dblp.org/rec/conf/deis/HuangC11> <https://dblp.org/pid/e/PaalEngelstad> 'RainSense: <https://dblp.org/pid/07/6566> <https://dblp.org/rec/journals/tie/BertoluzzoBM06> <https://dblp.org/rec/journals/js/YuCSAZF15> Formal <https://dblp.org/rec/journals/remotesensing/FanSQLFZ22> <https://dblp.org/pid/72/852> South <https://dblp.org/rec/conf/vl/Johnson03> != <https://dblp.org/rec/conf/fit/LatifNRF21>, Meas.' <https://dblp.org/pid/21/3666> <https://dblp.org/rec/journals/flap/Prosorov17> <https://dblp.org/pid/k/StefanosDKollias> <https://dblp.org/pid/36/6526> <https://dblp.org/rec/journals/ivc/LinGH94> <https://dblp.org/rec/journals/tie/SuhH97> <https://dblp.org/pid/m/TalMalkin> <https://dblp.org/rec/journals/ijcsm/Shao16> 'PACIS' <https://dblp.org/pid/50/3321> <https://dblp.org/pid/192/7270> <https://dblp.org/pid/70/4887> <https://dblp.org/pid/17/2660> <https://dblp.org/rec/conf/wcnc/RozarioHN11> <https://dblp.org/rec/conf/pdpta/JebaliM02> Mayuresh Cybernetics also <https://dblp.org/rec/journals/na/Sprengel98> 'MIT, <https://dblp.org/rec/conf/eumas/VuARF20> <https://dblp.org/pid/62/1791>\n",
            "Sample 1:\n",
            " ¿ SELECT ( COUNT( DISTINCT ?answer ) AS ?count ) WHERE { <https://dblp.org/rec/conf/pimrc/HaoYRAZ18> <https://dblp.org/rdf/schema#authoredBy> ?x . ?answer <https://dblp.org/rdf/schema#authoredBy> ?x } ¡ <https://dblp.org/rdf/schema#numberOfCreators> ?answer } ¡ ?answer } ¡ ?answer } ¡ ?answer ) AS ?count ) } ¡ <https://dblp.org/rec/journals/automatica/GueaiebAB07> != != != != != != != != != != !=\n",
            "Sample 2:\n",
            " ¿ SELECT DISTINCT ?answer WHERE { ?answer <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/63/5559> . ?answer <https://dblp.org/rdf/schema#yearOfPublication> ?y FILTER( ?y > YEAR( NOW(  ) )-5 ) } ¡ . ?answer ) } ¡ . ?x <https://dblp.org/rdf/schema#yearOfPublication> ?answer } ¡ != != != != != != != != != != != != != != !=\n",
            "Sample 3:\n",
            " ¿ SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/conf/icpram/ArmanoT15> <https://dblp.org/rdf/schema#authoredBy> ?x . <https://dblp.org/rec/conf/cec/ChiamML07> <https://dblp.org/rdf/schema#yearOfPublication> ?y . ?z <https://dblp.org/rdf/schema#authoredBy> ?x . ?z <https://dblp.org/rdf/schema#yearOfPublication> ?answer FILTER ( ?answer != ?y ) } ¡ . <https://dblp.org/rec/conf/wscg/ElHelwY03> } ¡ <https://dblp.org/rdf/schema#authoredBy> ?x . FILTER( ?answer FILTER ( ?answer } ¡ . FILTER ( ?answer FILTER NOT EXISTS\n",
            "Sample 4:\n",
            " ¿ ASK { <https://dblp.org/rec/conf/chi/Hersh82> <https://dblp.org/rdf/schema#authoredBy> ?x . ?y <https://dblp.org/rdf/schema#authoredBy> ?x FILTER ( ?y != <https://dblp.org/rec/conf/chi/Hersh82> <https://dblp.org/rdf/schema#authoredBy> ?x <https://dblp.org/rdf/schema#authoredBy> ?x <https://dblp.org/rdf/schema#publishedIn> 'GLOBECOM' } ¡ } ¡ <https://dblp.org/rdf/schema#authoredBy> ?x <https://dblp.org/rdf/schema#publishedIn> <https://dblp.org/rec/conf/greencom/SillastoWM10> ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ <https://dblp.org/rdf/schema#authoredBy> ?x\n",
            "Sample 5:\n",
            " ¿ SELECT DISTINCT ?answer WHERE { <https://dblp.org/rec/journals/jei/SchettiniGCMCC10> <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer } } ¡ } ¡ <https://dblp.org/rdf/schema#publishedIn> ?answer <https://dblp.org/rdf/schema#publishedIn> ?answer } ¡ } ¡ <https://dblp.org/rdf/schema#publishedIn> } ¡ . <https://dblp.org/rec/journals/amai/JohnsonM93> <https://dblp.org/rdf/schema#publishedIn> ?answer } } ¡ ?answer } ¡ ?answer } ¡ } ¡ != != != != != !=\n",
            "Sample 6:\n",
            " ¿ SELECT DISTINCT ?answer WHERE { ?answer <https://dblp.org/rdf/schema#authoredBy> <https://dblp.org/pid/01/10677> } ¡ ?answer } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ } ¡ != != != != != !=\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc1, acc3, mhd = test_model(n_test, m, word_encoder, word_decoder, test_data)\n",
        "print('Accuracy@1 on test: {}%'.format(acc1 * 100))\n",
        "print('Accuracy@3 on test: {}%'.format(acc3 * 100))\n",
        "print('Mean Hamming distance on test: {}'.format(mhd))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UMhNDPhv1aAq",
        "outputId": "6dc6d2d8-8336-48aa-c07e-86eda3a0e251"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Sample:  0\n",
            "Sample:  20\n",
            "Sample:  40\n",
            "Sample:  60\n",
            "Sample:  80\n",
            "Sample:  100\n",
            "Sample:  120\n",
            "Sample:  140\n",
            "Sample:  160\n",
            "Sample:  180\n",
            "Accuracy@1 on test: 31.892%\n",
            "Accuracy@3 on test: 43.784%\n",
            "Mean Hamming distance on test: 1.72432\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "final_queries = []\n",
        "for entry in linked_q:\n",
        "  n_tokens = MAX_OUT_BLOCK\n",
        "  in_t = torch.tensor(word_encoder(entry[\"linked\"]), dtype=torch.long)\n",
        "  padded_text = F.pad(in_t, (0, MAX_IN_BLOCK - len(in_t)), value=1)\n",
        "  query = word_decoder(m.generate(padded_text.unsqueeze(0).to(device), word_encoder('¿'), n_tokens)[0].tolist()[1:])\n",
        "  query = query.split(\"¡\")[0]\n",
        "  entry[\"sparql\"] = query\n",
        "  final_queries.append(entry)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/dblp_not_pretrained_queries_500.json\", 'w', encoding='utf-8') as file:\n",
        "  json.dump(final_queries, file)"
      ],
      "metadata": {
        "id": "aphuQbsZY3Fe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Qualitative testing"
      ],
      "metadata": {
        "id": "LTO0NNIhJukg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "q = \"What are the papers written by the person Hideaki Takeda?\"\n",
        "entities = [\"<https://dblp.org/pid/27/4034-1>\"]\n",
        "q = format_question(q)\n",
        "print(q)\n",
        "q = process_question(entities, q)\n",
        "print(q)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "F4gnZPdEBzjq",
        "outputId": "7b3e53ad-b61d-42ab-f316-6ae9f8c30406"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "what are the papers written by the person Hideaki Takeda\n",
            "what are the papers written by the person <https://dblp.org/pid/27/4034-1>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "n_tokens = 15\n",
        "in_t = torch.tensor(word_encoder(q), dtype=torch.long)\n",
        "padded_text = F.pad(in_t, (0, MAX_IN_BLOCK - len(in_t)), value=1)\n",
        "word_decoder(m.generate(padded_text.unsqueeze(0).to(device), word_encoder('¿'), n_tokens)[0].tolist()[1:])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 88
        },
        "id": "YLTUNw8FEZFB",
        "outputId": "d160a774-c2fa-419e-c28b-cd508489ff21"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"K. <https://dblp.org/rec/conf/cms/MerkelDV11> <https://dblp.org/pid/17/5121> <https://dblp.org/rec/conf/adc/LiuRB10> written <https://dblp.org/pid/81/930> <https://dblp.org/pid/149/6694> 'ICUIMC' <https://dblp.org/rec/journals/corr/abs-1712-00175> <https://dblp.org/pid/93/4244> NIPS <https://dblp.org/pid/14/9539> <https://dblp.org/rec/journals/winet/HojjatiEAN17> <https://dblp.org/rec/journals/rairo/AlrefaeiD15> <https://dblp.org/pid/258/3087>\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenge"
      ],
      "metadata": {
        "id": "Gr_ydNZgxAoM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install SPARQLWrapper"
      ],
      "metadata": {
        "id": "L4_v3sgqsQEg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import json, re\n",
        "from SPARQLWrapper import SPARQLWrapper, JSON\n",
        "\n",
        "def get_triples(query):\n",
        "  try:\n",
        "    sparql = SPARQLWrapper(\"https://dblp-kg.ltdemos.informatik.uni-hamburg.de/sparql\")\n",
        "    sparql.setQuery(query)\n",
        "    sparql.setReturnFormat(JSON)\n",
        "    results = sparql.query().convert()\n",
        "    triples = [a[\"answer\"][\"value\"] for a in results[\"results\"][\"bindings\"]]\n",
        "    return triples\n",
        "  except:\n",
        "    return []"
      ],
      "metadata": {
        "id": "wDXEXgXtrS_b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "with open(\"/content/drive/MyDrive/dblp_pretrained_queries_500.json\", 'r', encoding='utf-8') as file:\n",
        "  data = json.load(file)\n",
        "  for entry in data:\n",
        "    if entry[\"entities\"]:\n",
        "      query = entry[\"sparql\"]\n",
        "      answer = get_triples(query)\n",
        "      new_entry = entry.copy()\n",
        "      new_entry[\"answer\"] = answer\n",
        "      answers.append(new_entry)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/dblp_answers_pretrained_500.json\", 'w', encoding='utf-8') as file:\n",
        "  json.dump(answers, file)"
      ],
      "metadata": {
        "id": "Om7G-h5hcMpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "answers = []\n",
        "with open(\"/content/drive/MyDrive/dblp_not_pretrained_queries_500.json\", 'r', encoding='utf-8') as file:\n",
        "  data = json.load(file)\n",
        "  for entry in data:\n",
        "    if entry[\"entities\"]:\n",
        "      query = entry[\"sparql\"]\n",
        "      answer = get_triples(query)\n",
        "      new_entry = entry.copy()\n",
        "      new_entry[\"answer\"] = answer\n",
        "      answers.append(new_entry)\n",
        "\n",
        "with open(\"/content/drive/MyDrive/dblp_answers_not_pretrained_500.json\", 'w', encoding='utf-8') as file:\n",
        "  json.dump(answers, file)"
      ],
      "metadata": {
        "id": "HT5-2HJqrnTJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}